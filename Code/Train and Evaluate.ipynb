{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "from models import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Base directory as Capstone path\n",
    "dir_path=os.getcwd()\n",
    "try: \n",
    "    os.chdir(os.getcwd()[0:dir_path.index('Code')])\n",
    "except Exception:\n",
    "    print(Exception)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def CNN(self):\n",
      "        #frames_input = Input(shape=self.input_shape)\n",
      "        model = Sequential()\n",
      "        model.add(Conv2D(64, (1, 2), activation='relu', padding='same', input_shape=(10, 256, 38)))\n",
      "        model.add(MaxPooling2D((1, 2)))\n",
      "        model.add(Conv2D(64, (1, 2), activation='relu'))\n",
      "        model.add(MaxPooling2D((1, 2)))\n",
      "        model.add(Conv2D(128, (1, 2), activation='relu'))\n",
      "        model.add(MaxPooling2D((1, 2)))\n",
      "        model.add(Conv2D(128, (1, 2), activation='relu'))\n",
      "        model.add(MaxPooling2D((1, 2)))\n",
      "        model.add(Flatten())\n",
      "        model.add(Dense(512, activation='relu'))\n",
      "        model.add(Dense(1))\n",
      "        #model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
      "        #CNN = Model(inputs=frames_input, outputs=output)\n",
      "        return model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "source_DF = inspect.getsource(Model_List.CNN)\n",
    "\n",
    "print(source_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(IDs, yields, batch_size, cutoff=None):\n",
    "    import numpy as np\n",
    "    import random\n",
    "    \n",
    " # Create empty arrays to get batch of features and labels\n",
    "\n",
    "    if cutoff != None:\n",
    "        batch_features = np.zeros((batch_size, cutoff, 1, 256, 10))\n",
    "        batch_yields = np.zeros((batch_size))\n",
    "        while True:\n",
    "            for i in range(batch_size):\n",
    "                # choose random index in features\n",
    "                index = random.choice(range(len(IDs)))\n",
    "                ID = IDs[index]\n",
    "                if np.sum(np.isnan(np.load('Data/PROCESSED_III/' + ID + '.npy'))) == 0:\n",
    "                    batch_features[i, :, :, :, :] = np.load('Data/PROCESSED_III/' + ID + '.npy')[:cutoff, :, :, :]\n",
    "                    #print('yes', ID)\n",
    "                    batch_yields[i] = yields[ID]\n",
    "                else:\n",
    "                    print('no', ID)\n",
    "                    \n",
    "            yield batch_features, batch_yields\n",
    "                    \n",
    "    else:\n",
    "        batch_features = np.zeros((batch_size, 38, 1, 256, 10))\n",
    "        batch_yields = np.zeros((batch_size))\n",
    "        while True:\n",
    "            for i in range(batch_size):\n",
    "                # choose random index in features\n",
    "                index = random.choice(range(len(IDs)))\n",
    "                ID = IDs[index]\n",
    "                if np.sum(np.isnan(np.load('Data/PROCESSED_III/' + ID + '.npy'))) == 0:\n",
    "                    batch_features[i, :, :, :, :] = np.load('Data/PROCESSED_III/' + ID + '.npy')\n",
    "                    #print('yes', ID)\n",
    "                    batch_yields[i] = yields[ID]\n",
    "                else:\n",
    "                    print('no', ID)\n",
    "            yield batch_features, batch_yields\n",
    "            \n",
    "def generator_CNN(IDs, yields, batch_size, cutoff=None):\n",
    "    import numpy as np\n",
    "    import random\n",
    "    \n",
    " # Create empty arrays to get batch of features and labels\n",
    "\n",
    "    if cutoff != None:\n",
    "        batch_features = np.zeros((batch_size, cutoff, 256, 10))\n",
    "        batch_yields = np.zeros((batch_size))\n",
    "        while True:\n",
    "            for i in range(batch_size):\n",
    "                # choose random index in features\n",
    "                index = random.choice(range(len(IDs)))\n",
    "                ID = IDs[index]\n",
    "                if np.sum(np.isnan(np.load('Data/PROCESSED_IV/' + ID + '.npy'))) == 0:\n",
    "                    batch_features[i, :, :, :] = np.load('Data/PROCESSED_IV/' + ID + '.npy')[:cutoff, :, :]\n",
    "                    #print('yes', ID)\n",
    "                    batch_yields[i] = yields[ID]\n",
    "                else:\n",
    "                    print('no', ID)\n",
    "                    \n",
    "            yield batch_features, batch_yields\n",
    "                    \n",
    "    else:\n",
    "        batch_features = np.zeros((batch_size, 38, 256, 10))\n",
    "        batch_yields = np.zeros((batch_size))\n",
    "        while True:\n",
    "            for i in range(batch_size):\n",
    "                # choose random index in features\n",
    "                index = random.choice(range(len(IDs)))\n",
    "                ID = IDs[index]\n",
    "                if np.sum(np.isnan(np.load('Data/PROCESSED_IV/' + ID + '.npy'))) == 0:\n",
    "                    batch_features[i, :, :, :] = np.load('Data/PROCESSED_IV/' + ID + '.npy')\n",
    "                    #print('yes', ID)\n",
    "                    batch_yields[i] = yields[ID]\n",
    "                else:\n",
    "                    print('no', ID)\n",
    "            yield batch_features, batch_yields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 9\n",
      "Loading Model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 10, 256, 64)       4928      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 128, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 127, 64)       8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 10, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 62, 128)       16512     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 10, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 30, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 10, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 19200)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               9830912   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 9,894,017\n",
      "Trainable params: 9,894,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vinayak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\Vinayak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=84.5625, verbose=0, steps_per_epoch=5, epochs=50)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00025: early stopping\n",
      "4.95  mins\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# training model on data of year 2010-2015 (6 years total)\n",
    "\n",
    "#model_list = ['CNN_LSTM', 'SepCNN_LSTM', 'CONVLSTM']\n",
    "model_list = ['CNN_AVG','CNN_AVG_small']\n",
    "\n",
    "#Get Datasets\n",
    "yields = pickle.load(open('Data/yields.p', 'rb'))\n",
    "y = yields\n",
    "print(len(yields['train']), len(yields['validation']))\n",
    "\n",
    "# Early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, \\\n",
    "                          verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]\n",
    "\n",
    "# generators\n",
    "#training_generator = generator(list(y['train'].keys()), y['train'], 16)\n",
    "#validation_generator = generator(list(y['validation'].keys()), y['validation'], 16)\n",
    "\n",
    "for model_name in model_list:\n",
    "    if model_name in model_list:\n",
    "        training_generator = generator_CNN(list(y['train'].keys()), y['train'], 64)\n",
    "        validation_generator = generator_CNN(list(y['validation'].keys()), y['validation'], 64)\n",
    "    else:\n",
    "        training_generator = generator(list(y['train'].keys()), y['train'], 64)\n",
    "        validation_generator = generator(list(y['validation'].keys()), y['validation'], 64)\n",
    "    rm = Model_List(model_name, 38, (1, 256, 10), print_model=True)   \n",
    "    history=rm.model.fit_generator(training_generator, validation_data=validation_generator, \\\n",
    "                                   callbacks= callbacks_list, \\\n",
    "                               validation_steps=50, steps_per_epoch=100, nb_epoch=30, verbose=0)\n",
    "    print (model_name)\n",
    "    mae = history.history['mean_absolute_error']\n",
    "    val_mae = history.history['val_mean_absolute_error']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(mae) + 1)\n",
    "    plt.plot(epochs, mae, 'bo', label='Training mae')\n",
    "    plt.plot(epochs, val_mae, 'b', label='Validation mae')\n",
    "    plt.title('Training and validation MAE')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    rm.model.save(model_name)\n",
    "end = time.time()\n",
    "print(int(end - start)/60,' mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Vinayak\\\\Downloads\\\\CBA\\\\Capstone'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-301245dd29b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#history=model.fit_generator(training_generator, validation_data=validation_generator, callbacks=callbacks_list,\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#                               validation_steps=1353/16, samples_per_epoch=5, nb_epoch=50, verbose=0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_absolute_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mval_mae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_mean_absolute_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#rm = Model_List('No model', 38, (1, 256, 10), saved_model=model_name)\n",
    "history = load_model('CNN')\n",
    "#history=model.fit_generator(training_generator, validation_data=validation_generator, callbacks=callbacks_list,\\\n",
    "#                               validation_steps=1353/16, samples_per_epoch=5, nb_epoch=50, verbose=0)\n",
    "mae = history.history['mean_absolute_error']\n",
    "val_mae = history.history['val_mean_absolute_error']\n",
    "loss = history.history['loss']\n",
    "#al_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model CNN\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_5_input to have 4 dimensions, but got array with shape (9, 38, 1, 256, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8743972c1c89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mrm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel_List\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m38\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mabs_error\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'For model {}, the test mean absolute error is {:.2f}.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabs_error\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_5_input to have 4 dimensions, but got array with shape (9, 38, 1, 256, 10)"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Model Evaluation on the yields of paddy yields across India in year 2016\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(42)\n",
    "\n",
    "test_gen = generator(list(yields['validation'].keys()), yields['validation'], len(yields['validation']))\n",
    "X_test, y_test = next(test_gen)\n",
    "abs_error = np.empty(len(model_list))\n",
    "\n",
    "for i, model_name in enumerate(model_list):\n",
    "    rm = Model_List('No model', 38, (1, 256, 10), saved_model=model_name)\n",
    "    abs_error[i] = rm.model.evaluate(X_test, y_test, batch_size=16)[0]\n",
    "    print('For model {}, the test mean absolute error is {:.2f}.'.format(model_name, abs_error[i]))\n",
    "\n",
    "best_model = model_list[np.argmin(abs_error)]\n",
    "print('The best model is {}.'.format(best_model))\n",
    "end = time.time()\n",
    "print(int(end - start)/60,' mins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "####################\n",
    "\n",
    "batch_size = [8, 32, 64]\n",
    "abs_error_batch = np.empty(len(batch_size))\n",
    "\n",
    "for i, size in enumerate(batch_size):\n",
    "    # generators\n",
    "    training_generator = generator(list(y['train'].keys()), y['train'], size)\n",
    "    validation_generator = generator(list(y['validation'].keys()), y['validation'], size)\n",
    "\n",
    "    rm = Model_List('None', 38, (1, 256, 10), saved_model=best_model)\n",
    "    rm.model.fit_generator(training_generator, validation_data=validation_generator, callbacks=callbacks_list,\\\n",
    "                               validation_steps=1353/size, samples_per_epoch=50, nb_epoch=10, verbose=0)\n",
    "\n",
    "    abs_error_batch[i] = rm.model.evaluate(X_test, y_test, batch_size=size)[1]\n",
    "    print('For batch {}, the test mean absolute error is {:.2f}.'.format(size, abs_error_batch[i]))\n",
    "    \n",
    "    rm.model.save(best_model + '_' + str(size))\n",
    "print(int(time.time() - start)/60,' mins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing the number of frames per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "########################\n",
    "n_frames = [1, 5, 10, 15, 20, 25, 30, 35]\n",
    "abs_error_frames = np.empty(len(n_frames))\n",
    "i = 0\n",
    "\n",
    "for frame in n_frames:\n",
    "    # generators\n",
    "    print('Doing {} frames per year'.format(frame))\n",
    "    training_generator = generator(list(y['train'].keys()), y['train'], 16, cutoff=frame)\n",
    "    validation_generator = generator(list(y['validation'].keys()), y['validation'], 16, cutoff=frame)\n",
    "    \n",
    "    test_gen = generator(list(yields['validation'].keys()), yields['validation'], len(yields['validation']), cutoff=frame)\n",
    "    X_test, y_test = next(test_gen)\n",
    "\n",
    "    rm = Model_List('CNN_LSTM', frame, (1, 256, 10))\n",
    "    rm.model.fit_generator(training_generator, validation_data=validation_generator, callbacks=callbacks_list,\\\n",
    "                               validation_steps=1353/16, samples_per_epoch=50, nb_epoch=10, verbose=0)\n",
    "    abs_error_frames[i] = rm.model.evaluate(X_test, y_test, batch_size=16)[1]\n",
    "    \n",
    "    rm.model.save('CNN_LSTM' + '_' + str(frame))\n",
    "    print('For {} frames per year, the test mean absolute error is {:.2f}.'.format(frame, abs_error_frames[i]))\n",
    "    i += 1\n",
    "    pickle.dump( abs_error_frames, open( \"abs_error_framess.p\", \"wb\" ) )\n",
    "\n",
    "######################## \n",
    "print(int(time.time() - start)/60,' mins')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
